{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba52741",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "[melb_data.csv](https://www.kaggle.com/code/dansbecker/your-first-machine-learning-model/data?select=melb_data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87794b79",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab53fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d99fe",
   "metadata": {},
   "source": [
    "# 1st ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3283cfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melbourne_data = pd.read_csv('data/melb_data.csv')\n",
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c448be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17363cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourne_data[['Rooms','Bathroom','Landsize','Lattitude','Longtitude']]\n",
    "y = melbourne_data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990aeb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
      "1      2       1.0     156.0   -37.8079    144.9934\n",
      "2      3       2.0     134.0   -37.8093    144.9944\n",
      "4      4       1.0     120.0   -37.8072    144.9941\n",
      "6      3       2.0     245.0   -37.8024    144.9993\n",
      "7      2       1.0     256.0   -37.8060    144.9954\n",
      "[1035000. 1465000. 1600000. 1876000. 1636000.]\n"
     ]
    }
   ],
   "source": [
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "melbourne_model.fit(X,y)\n",
    "print(X.head())\n",
    "print(melbourne_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be619f4",
   "metadata": {},
   "source": [
    "# Model validation\n",
    "*Tree's depth is a measure of how many splits im makes before coming to a prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c97898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115.7467183128902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa66973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274447.0757477943\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "melbourne_model.fit(X_train, y_train)\n",
    "\n",
    "predicitons = melbourne_model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, predicitons))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e4e769",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting\n",
    "\n",
    "- `overfitting` - when a model matches the training data almost perfectly, but does poorly in validation and other new data, capturing spurious patterns that won't recur in the future, leading to less accurate predictions <br> <br>\n",
    "- `underfitting` - when a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, failing to capture relevant patterns, again leading to less accurate predictions. <br> <br>\n",
    "\n",
    "**max_leaf_nodes** provides a very sensible way to control overfitting and underfitting in decision trees. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88df7568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  385696\n",
      "Max leaf nodes: 25  \t\t Mean Absolute Error:  307919\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  279794\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  269191\n",
      "Max leaf nodes: 250  \t\t Mean Absolute Error:  269945\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  261718\n"
     ]
    }
   ],
   "source": [
    "def get_mae(n):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=n, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    return mae\n",
    "\n",
    "for max_leaf_nodes in [5, 25, 50, 100, 250, 500]:\n",
    "    my_mae = get_mae(max_leaf_nodes)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646df34",
   "metadata": {},
   "source": [
    "You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size.\n",
    "\n",
    "*In binary tree if there is n leaf nodes there is also n-1 \"splits\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d34c111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = DecisionTreeRegressor(max_leaf_nodes=100)\n",
    "final_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d163de",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77209f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207190.6873773146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X_train, y_train)\n",
    "pred = forest_model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
