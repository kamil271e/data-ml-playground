{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2257ce89-0f47-450f-ab67-5f6fc27119a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dense, Embedding, LSTM, concatenate, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Sequential, Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7b1bd0-f7ed-413d-8ecc-5494e8243e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple NN\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(64,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99c9afc-7005-4430-9c5c-a95d3ea9e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# equivalent NN using functional API\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = Dense(32, activation='relu')(input_tensor)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_tensor = Dense(10, activation='softmax')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc6c34-91a2-4b6b-8d45-fbc90b009314",
   "metadata": {},
   "source": [
    "## Multiple input models\n",
    "Network which gets question and reference text as an input and outputs an answer to that question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65349d-e15d-452a-b829-a83f83a5c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer) # you can also pass a dictionary\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe77f53-2dc9-4068-b1e7-42d8049e3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9958281d-60c5-4f65-968f-ba91ef7aa48f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_vocabulary_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[43mtext_vocabulary_size\u001b[49m, size\u001b[38;5;241m=\u001b[39m(num_samples, max_len))\n\u001b[1;32m      2\u001b[0m question \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, question_vocabulary_size, size\u001b[38;5;241m=\u001b[39m(num_samples, max_len))\n\u001b[1;32m      3\u001b[0m answers \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39m(num_samples, answer_vocabulary_size))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_vocabulary_size' is not defined"
     ]
    }
   ],
   "source": [
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_len))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_len))\n",
    "answers = np.random.randint(0, 2, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128, verbose=0)\n",
    "# model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c0c7f-2f60-4fd8-823c-e4999d4f10e4",
   "metadata": {},
   "source": [
    "## Multiple output models\n",
    "Network that takes as an input some statement from social media and predict age, income and gender of an author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9e25c0f-135b-4078-9fc5-19de218ff856",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "age_pred = Dense(1, name='age')(x)\n",
    "income_pred = Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_pred = Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_pred, income_pred, gender_pred])\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss=['mae', 'sparse_categorical_crossentropy', 'binary_crossentropy']) # you can also use dictionary with keys: age, gender, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b0e200e-a5a1-4d47-bf97-77898d545719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 23.9978 - age_loss: 20.4890 - income_loss: 2.7027 - gender_loss: 0.8061 - age_accuracy: 0.0000e+00 - income_accuracy: 0.1260 - gender_accuracy: 0.5030\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 20.2176 - age_loss: 16.8574 - income_loss: 2.5867 - gender_loss: 0.7735 - age_accuracy: 0.0000e+00 - income_accuracy: 0.1040 - gender_accuracy: 0.5110\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 4s 482ms/step - loss: 13.7427 - age_loss: 10.6099 - income_loss: 2.3650 - gender_loss: 0.7678 - age_accuracy: 0.0000e+00 - income_accuracy: 0.1120 - gender_accuracy: 0.5070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f30484310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples,500))\n",
    "target_age = np.random.randint(18, 99, size=num_samples)\n",
    "target_income = np.random.randint(1, 10, size=num_samples)\n",
    "target_gender = np.random.randint(0, 2, size=num_samples)\n",
    "\n",
    "model.fit(posts, [target_age, target_income, target_gender], batch_size=128, epochs=3) # or with dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eae59b-d0ec-46da-af81-dea091734504",
   "metadata": {},
   "source": [
    "## Directed acyclic graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000153e9-be02-48e2-af6d-b7cdb7de115a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science] *",
   "language": "python",
   "name": "conda-env-data_science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
