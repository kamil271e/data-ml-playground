{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2257ce89-0f47-450f-ab67-5f6fc27119a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input\n",
    "from keras.layers import Dense, Embedding, LSTM, concatenate, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Conv2D, AveragePooling2D, add, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications import Xception\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b7b1bd0-f7ed-413d-8ecc-5494e8243e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple NN\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(64,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99c9afc-7005-4430-9c5c-a95d3ea9e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# equivalent NN using functional API\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = Dense(32, activation='relu')(input_tensor)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output_tensor = Dense(10, activation='softmax')(x)\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc6c34-91a2-4b6b-8d45-fbc90b009314",
   "metadata": {},
   "source": [
    "## Multiple input models\n",
    "Network which gets question and reference text as an input and outputs an answer to that question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca65349d-e15d-452a-b829-a83f83a5c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " question (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     640000      ['text[0][0]']                   \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 32)     320000      ['question[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           12416       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 16)           3136        ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 48)           0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 500)          24500       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = Embedding(text_vocabulary_size, 64)(text_input)\n",
    "encoded_text = LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer) # you can also pass a dictionary\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe77f53-2dc9-4068-b1e7-42d8049e3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9958281d-60c5-4f65-968f-ba91ef7aa48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4b0204190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_len))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_len))\n",
    "answers = np.random.randint(0, 2, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128, verbose=0)\n",
    "# model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c0c7f-2f60-4fd8-823c-e4999d4f10e4",
   "metadata": {},
   "source": [
    "## Multiple output models\n",
    "Network that takes as an input some statement from social media and predict age, income and gender of an author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e25c0f-135b-4078-9fc5-19de218ff856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " posts (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, None, 256)    12800000    ['posts[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, None, 128)    163968      ['embedding_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, None, 128)   0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, None, 256)    164096      ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, None, 256)    327936      ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, None, 256)   0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, None, 256)    327936      ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, None, 256)    327936      ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 256)         0           ['conv1d_14[0][0]']              \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          32896       ['global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            129         ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " income (Dense)                 (None, 10)           1290        ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " gender (Dense)                 (None, 1)            129         ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = Conv1D(256, 5, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "age_pred = Dense(1, name='age')(x)\n",
    "income_pred = Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_pred = Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_pred, income_pred, gender_pred])\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss=['mae', 'sparse_categorical_crossentropy', 'binary_crossentropy']) # you can also use dictionary with keys: age, gender, income\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0e200e-a5a1-4d47-bf97-77898d545719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8/8 [==============================] - 5s 472ms/step - loss: 49.2611 - age_loss: 44.0599 - income_loss: 4.3533 - gender_loss: 0.8479 - age_accuracy: 0.0000e+00 - income_accuracy: 0.0980 - gender_accuracy: 0.4780\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 4s 488ms/step - loss: 32.8707 - age_loss: 28.3471 - income_loss: 3.7171 - gender_loss: 0.8065 - age_accuracy: 0.0000e+00 - income_accuracy: 0.1130 - gender_accuracy: 0.4920\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 4s 502ms/step - loss: 24.7936 - age_loss: 20.3835 - income_loss: 3.4938 - gender_loss: 0.9163 - age_accuracy: 0.0000e+00 - income_accuracy: 0.1100 - gender_accuracy: 0.5080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe44bf56410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples,500))\n",
    "target_age = np.random.randint(18, 99, size=num_samples)\n",
    "target_income = np.random.randint(1, 10, size=num_samples)\n",
    "target_gender = np.random.randint(0, 2, size=num_samples)\n",
    "\n",
    "model.fit(posts, [target_age, target_income, target_gender], batch_size=128, epochs=3) # or with dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eae59b-d0ec-46da-af81-dea091734504",
   "metadata": {},
   "source": [
    "## Directed acyclic graphs\n",
    "Inception architecture example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd04421-423b-4c50-abad-e83f5dcde6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(None,28,28))\n",
    "\n",
    "branch_a = Conv2D(128, 1, activation='relu', strides=2)(input_tensor)\n",
    "#print(branch_a.shape)\n",
    "\n",
    "branch_b = Conv2D(128, 1, activation='relu')(input_tensor)\n",
    "branch_b = Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b)\n",
    "branch_b = Conv2D(128, 1, activation='relu')(branch_b)\n",
    "#print(branch_b.shape)\n",
    "\n",
    "branch_c = AveragePooling2D(3, strides=2, padding='same')(input_tensor)\n",
    "branch_c = Conv2D(128, 1, activation='relu')(branch_c)\n",
    "#print(branch_c.shape)\n",
    "\n",
    "branch_d = Conv2D(128, 1, activation='relu')(input_tensor)\n",
    "branch_d = Conv2D(128, 3, activation='relu', padding='same')(branch_d)\n",
    "branch_d = Conv2D(128, 1, activation='relu')(branch_d)\n",
    "branch_d = Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_d)\n",
    "branch_d = Conv2D(128, 1, activation='relu')(branch_d)\n",
    "#print(branch_d.shape)\n",
    "\n",
    "output = concatenate([branch_a, branch_b, branch_c, branch_d],axis=-1)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac15fe-9a9f-488a-a6ee-cc296a4e2ffc",
   "metadata": {},
   "source": [
    "## Residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb283891-c75b-4197-9ecd-0ab34a2aa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(32,32,128))\n",
    "y = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = add([y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60c620b-6714-4eb3-b191-2006eefb54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(32,32,3))\n",
    "y = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = Conv2D(128, 1, strides=2, padding='same')(x) # to have the same shapes\n",
    "\n",
    "y = add([y, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1306262-77cd-48a8-a7b6-378d23fcc8f3",
   "metadata": {},
   "source": [
    "## Shared layers\n",
    "Semantic similarity example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdc3a1e4-ba5b-46ad-ba1b-ff90ef22fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(32)\n",
    "\n",
    "left_input = Input(shape=(None,128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None,128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = concatenate([left_output, right_output], axis=-1)\n",
    "predictions = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "\n",
    "# model.fit([right_data, left_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957fe66-7adb-4a5b-ba4d-2471551930f7",
   "metadata": {},
   "source": [
    "## Models as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd26f39b-d63e-436e-a201-da1a431d30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_base = Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250,250,3))\n",
    "right_input = Input(shape=(250,250,3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "rigth_features = xception_base(right_input)\n",
    "\n",
    "merged_features = concatenate([left_features, rigth_features], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science] *",
   "language": "python",
   "name": "conda-env-data_science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
